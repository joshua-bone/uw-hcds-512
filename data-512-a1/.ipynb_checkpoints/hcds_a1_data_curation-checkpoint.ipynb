{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L92A0_JOPSDt"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import datetime as dt\n",
    "from enum import Enum\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Dq2Lef7tvOOd"
   },
   "outputs": [],
   "source": [
    "# WORKFLOW CONFIGURATION\n",
    "# If True, does not attempt to make any API calls, and instead uses the raw API\n",
    "# results stored in cached JSON files in the same directory as this notebook.\n",
    "# Useful if running the notebook locally or if API is not available. If False, \n",
    "# calls the APIs and overwrites the JSON files in this directory. \n",
    "USE_CACHED_API_RESULTS = False\n",
    "\n",
    "# API CONFIGURATION\n",
    "# If desired, these timestamps can be modified to rerun the workflow over \n",
    "# different time windows.\n",
    "EARLIEST_TIMESTAMP, LATEST_TIMESTAMP = \"2007010100\", \"2018100100\"\n",
    "\n",
    "# CSV CONFIGURATION\n",
    "# Column names for the CSV file.\n",
    "YEAR, MONTH = \"year\", \"month\"\n",
    "CTR_LGC_ALL = \"pagecount_all_views\"\n",
    "CTR_LGC_DTP = \"pagecount_desktop_views\"\n",
    "CTR_LGC_MBL = \"pagecount_mobile_views\"\n",
    "CTR_PGV_ALL = \"pageview_all_views\"\n",
    "CTR_PGV_DTP = \"pageview_desktop_views\"\n",
    "CTR_PGV_MBL = \"pageview_mobile_views\"\n",
    "# String constants declared just to avoid typos.\n",
    "LEGACY, PAGEVIEW, DESKTOP, MOBILE = \"legacy\", \"pageview\", \"desktop\", \"mobile\"\n",
    "# Data structures to organize and map the column names for easy handling later.\n",
    "# Map the api type to its associated total sum counter \n",
    "SUM_CTR = {LEGACY : CTR_LGC_ALL, PAGEVIEW : CTR_PGV_ALL}\n",
    "# Map the api and platform types to their associated individual counters.\n",
    "INDIV_CTR = {LEGACY : {DESKTOP : CTR_LGC_DTP, MOBILE : CTR_LGC_MBL},\n",
    "            PAGEVIEW : {DESKTOP : CTR_PGV_DTP, MOBILE : CTR_PGV_MBL}}\n",
    "# Order the column names that are counters for easy iteration.\n",
    "CSV_COUNTERS = [CTR_LGC_ALL, \n",
    "                CTR_LGC_DTP, \n",
    "                CTR_LGC_MBL, \n",
    "                CTR_PGV_ALL, \n",
    "                CTR_PGV_DTP, \n",
    "                CTR_PGV_MBL]\n",
    "# Order all of the headers for the CSV file according to the required spec.\n",
    "CSV_HEADERS = [YEAR, MONTH] + CSV_COUNTERS\n",
    "\n",
    "\n",
    "# API CONSTANTS\n",
    "HEADERS = {'User-Agent': 'https://github.com/joshua-bone',\n",
    "           'From': 'joshbone@uw.edu'}\n",
    "JSON_FILENAME_FORMAT = \"{}_{}_{}-{}.json\"\n",
    "CSV_FILENAME_FORMAT = \"en-wikipedia_traffic_{}-{}.csv\"\n",
    "LGC_DTP, LGC_MBL = \"desktop-site\", \"mobile-site\"\n",
    "PGV_DTP, MBL_WEB, MBL_APP = \"desktop\", \"mobile-web\", \"mobile-app\"\n",
    "LGC_ACCESS = [LGC_DTP, LGC_MBL]\n",
    "PGV_ACCESS = [PGV_DTP, MBL_WEB, MBL_APP]\n",
    "DTP_ACCESS = [LGC_DTP, PGV_DTP]\n",
    "PROJECT, GRANULARITY = \"en.wikipedia.org\", \"monthly\"\n",
    "\n",
    "# Explicitly filter out bot traffic (in the Pageviews API only).\n",
    "AGENT = \"user\"\n",
    "\n",
    "ENDPOINT_LGC = ('https://wikimedia.org/api/rest_v1/'\n",
    "                   'metrics/legacy/pagecounts/aggregate/'\n",
    "                   '{project}/{access-site}/{granularity}/{start}/{end}')\n",
    "\n",
    "ENDPOINT_PGV = ('https://wikimedia.org/api/rest_v1/'\n",
    "                      'metrics/pageviews/aggregate/'\n",
    "                      '{project}/{access}/{agent}/{granularity}/{start}/{end}')\n",
    "\n",
    "# ARTIFACT CONSTANTS\n",
    "TITLE=\"Page Views On English Wikipedia (x 1,000,000)\"\n",
    "XLABEL=\"Year\"\n",
    "YLABEL=\"Views\"\n",
    "VIZ_FILENAME = \"hcds-a1-visualization.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bSnVXmjDEs-f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Constructs a set of parameters for calling either of the two APIs. The API to\n",
    "# call is inferred from the access level. \n",
    "def params(access, start, end):\n",
    "  result = {\"project\" : PROJECT,\n",
    "            \"granularity\" : GRANULARITY,\n",
    "            \"start\" : start,\n",
    "            \"end\" : end}\n",
    "  if access in LGC_ACCESS:\n",
    "    result[\"access-site\"] = access\n",
    "  else:\n",
    "    result[\"access\"] = access\n",
    "    result[\"agent\"] = AGENT\n",
    "  return result\n",
    "\n",
    "# Calls the correct API for the given access level. Optional parameters 'start'\n",
    "# and 'end' can be used to modify the time window if needed.\n",
    "def call_api(access, start = EARLIEST_TIMESTAMP, end = LATEST_TIMESTAMP):\n",
    "  endpoint = ENDPOINT_LGC if access in LGC_ACCESS else ENDPOINT_PGV\n",
    "  return requests.get(endpoint.format(**params(access, start, end)), \n",
    "                      headers=HEADERS).json()\n",
    "\n",
    "# Returns a 6-digit integer representing the year and month from a string\n",
    "# timestamp [for example, year_and_month_from(\"2010060800\") = 201006].\n",
    "def year_and_month_from(timestamp):\n",
    "  return int(timestamp) // 10000 # use integer division\n",
    "\n",
    "# Constructs a correctly formatted JSON filename for the given parameters.\n",
    "def json_filename(access, start = EARLIEST_TIMESTAMP, end = LATEST_TIMESTAMP):\n",
    "  api = \"pagecounts\" if access in LGC_ACCESS else \"pageviews\"\n",
    "  return JSON_FILENAME_FORMAT.format(api, \n",
    "                                     access, \n",
    "                                     year_and_month_from(start), \n",
    "                                     year_and_month_from(end) - 1)\n",
    "\n",
    "# Constructs a correctly formatted CSV file name for the given parameters.\n",
    "def csv_filename(start = EARLIEST_TIMESTAMP, end = LATEST_TIMESTAMP):\n",
    "  return CSV_FILENAME_FORMAT.format(year_and_month_from(start), \n",
    "                                    year_and_month_from(end) - 1)\n",
    "\n",
    "# Calls the correct API for the given access level, and writes a JSON file with\n",
    "# a correctly formatted filename.\n",
    "def call_api_and_write_raw_data(access):\n",
    "  api_result = call_api(access)\n",
    "  with open(json_filename(access), \"w\") as f:\n",
    "    f.write(json.dumps(api_result))\n",
    "    \n",
    "if not USE_CACHED_API_RESULTS:\n",
    "  # Call the appropriate API for each of the five access levels, and write the\n",
    "  # raw data to JSON.\n",
    "    map(call_api_and_write_raw_data, LGC_ACCESS + PGV_ACCESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "WqH0jSUd4-ZG"
   },
   "outputs": [],
   "source": [
    "# Extract the string year and month values from a string timestamp.\n",
    "year_from = lambda timestamp : timestamp[0:4]\n",
    "month_from = lambda timestamp : timestamp[4:6]\n",
    "\n",
    "# Initialize a new row with zeroed counters for a timestamp\n",
    "def new_csv_row_from_timestamp(timestamp):\n",
    "  row = {YEAR: year_from(timestamp), MONTH: month_from(timestamp)}\n",
    "  row.update({counter : 0 for counter in CSV_COUNTERS})\n",
    "  return row\n",
    "\n",
    "# Return the CSV counters to increment for a given access level. For example,\n",
    "# access 'mobile-app' should increment both 'pageview_mobile_views' and \n",
    "# 'pageview_all_views'\n",
    "def counters_to_increment(access):\n",
    "  api = LEGACY if access in LGC_ACCESS else PAGEVIEW\n",
    "  platform = DESKTOP if access in DTP_ACCESS else MOBILE\n",
    "  return [SUM_CTR[api], INDIV_CTR[api][platform]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "csoZ-UZXwu5l",
    "outputId": "5cde6597-9981-48bc-bae7-f0ba7aff1950"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pagecounts_desktop-site_200701-201809.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-2d5d1b1760ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0maccess\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mLGC_ACCESS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mPGV_ACCESS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mraw_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccess\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pagecounts_desktop-site_200701-201809.json'"
     ]
    }
   ],
   "source": [
    "# Read the raw data in from JSON files\n",
    "raw_data = {}\n",
    "for access in LGC_ACCESS + PGV_ACCESS:\n",
    "  with open(json_filename(access), \"r\") as f:\n",
    "    raw_data[access] = json.load(f)\n",
    "\n",
    "cleaned_data = {}\n",
    "# Loop through all five access levels.\n",
    "for access in raw_data:\n",
    "  # Loop through all buckets in each access level. Each bucket contains one\n",
    "  # month of data.\n",
    "  for bucket in raw_data[access]['items']:\n",
    "    timestamp = bucket['timestamp']\n",
    "\n",
    "    # The two APIs have different headers for total count. Make sure we get the\n",
    "    # right one.\n",
    "    count = bucket['count'] if access in LGC_ACCESS else bucket['views']\n",
    "    \n",
    "    # Initialize a new row with zeroed counters if we haven't seen this \n",
    "    # timestamp yet.\n",
    "    if timestamp not in cleaned_data:\n",
    "      cleaned_data[timestamp] = new_csv_row_from_timestamp(timestamp)\n",
    "      \n",
    "    # Increment the correct counters for this access level with the count from\n",
    "    # this api bucket.\n",
    "    csv_row = cleaned_data[timestamp]\n",
    "    for counter in counters_to_increment(access):\n",
    "      csv_row[counter] += count // 1_000_000 # Record views by millions\n",
    "\n",
    "# Write cleaned data to CSV\n",
    "with open(csv_filename(), 'w') as f:\n",
    "  writer = csv.writer(f)\n",
    "  \n",
    "  # Write the column names to the first row in the CSV file.\n",
    "  writer.writerow(CSV_HEADERS)\n",
    "  \n",
    "  # Loop through each month of cleaned data in increasing chronological order.\n",
    "  for timestamp in sorted(cleaned_data.keys()):\n",
    "    \n",
    "    # Write the values for each month to the CSV file, in the same order as the\n",
    "    # column names were written.\n",
    "    row = map(lambda column : cleaned_data[timestamp][column], CSV_HEADERS)\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "xyGPgJaWGRCy"
   },
   "outputs": [],
   "source": [
    "first_of_year = lambda t : pd.Timestamp(t.year, 1, 1)\n",
    "first_of_next_year = lambda t : pd.Timestamp(t.year + 1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "colab_type": "code",
    "id": "zuAE_SrA1Dh9",
    "outputId": "2b30c0fb-e3eb-42b3-b4b4-5acd56a73f78"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'en-wikipedia_traffic_200701-201809.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-fb1b3db4d965>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Read cleaned data from CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Construct a new column from the year and month of the old column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'en-wikipedia_traffic_200701-201809.csv' does not exist"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNWLIwgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1141f9780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATE = \"Date\"\n",
    "fig, ax = plt.subplots()\n",
    "TITLE_FONT_SIZE = 20\n",
    "LABEL_FONT_SIZE = 15\n",
    "INFO = 'May 2015: a new pageview definition took effect, which eliminated all' \\\n",
    "       + 'crawler traffic. Solid lines mark new definition.'\n",
    "\n",
    "\n",
    "# The first and last buckets returned by the legacy API show much lower numbers\n",
    "# than the other buckets, likely because data was recorded for only part of the\n",
    "# month. We remove these numbers to avoid having distracting dips in the plot.\n",
    "LGC_PARTIAL_DATES = [\"2007-12-01\", \"2016-08-01\"]\n",
    "\n",
    "# Read cleaned data from CSV\n",
    "df = pd.read_csv(csv_filename())\n",
    "\n",
    "# Construct a new column from the year and month of the old column\n",
    "df[DATE] = df.apply(lambda row : dt.datetime(row[YEAR], row[MONTH], 1), axis=1)\n",
    "df.drop([YEAR, MONTH], axis=1, inplace=True)\n",
    "df.replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Remove all legacy numbers for 2016-08-01 since it is a partial month.\n",
    "legacy_counters = [CTR_LGC_ALL, CTR_LGC_DTP, CTR_LGC_MBL]\n",
    "for partial_date in LGC_PARTIAL_DATES:\n",
    "  df.loc[df[DATE] == partial_date, legacy_counters] = np.nan\n",
    "\n",
    "# Dynamically set the bounds for x- and y- axes.\n",
    "xmin = first_of_year(df[DATE].min())\n",
    "xmax = first_of_next_year(df[DATE].max())\n",
    "# For the y-axis, round the maximum value in the data to the nearest 1000, and \n",
    "# then add 1000 to define the upper bound for the y-axis.\n",
    "ymax = round(df.loc[:, df.columns[0:6]].max().max(), -3) + 1000\n",
    "\n",
    "# The x-axis should have ticks for the beginning of each year.\n",
    "xticklabels = range(xmin.year, xmax.year + 1)\n",
    "xticks = [pd.Timestamp(year, 1, 1) for year in xticklabels]\n",
    "\n",
    "# Define the date column to be along the x-axis.\n",
    "df.set_index(DATE, inplace=True)\n",
    "\n",
    "# Prepare to plot the data.\n",
    "colors = ['k', 'g', 'b'] * 2\n",
    "line_styles = np.repeat(['--', '-'], [3, 3])\n",
    "x = fig.set_size_inches(18, 6)\n",
    "# Reverse everything so that the 'total' lines end up on top of the 'mobile'\n",
    "# and 'desktop' lines. Plot the data.\n",
    "for column, style, color in zip(reversed(df.columns[0:6]), \n",
    "                             reversed(line_styles), \n",
    "                             reversed(colors)):\n",
    "  df[column].plot(style=style+color,\n",
    "                  ax=ax, \n",
    "                  xticks=xticks, \n",
    "                  xlim=(xmin, xmax),\n",
    "                  ylim=(0, ymax))\n",
    "  \n",
    "# Adjust the axes, title, font sizes, and legends. \n",
    "ax.set_xticklabels(xticklabels, fontsize=LABEL_FONT_SIZE)\n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "  tick.label.set_fontsize(LABEL_FONT_SIZE)\n",
    "ax.set_title(TITLE, fontsize=TITLE_FONT_SIZE)\n",
    "plt.xlabel(INFO, color='red',  fontsize=LABEL_FONT_SIZE)\n",
    "legend = ax.legend((ax.lines[4], ax.lines[3], ax.lines[5]), \n",
    "              ('main site', 'mobile site', 'total'))\n",
    "p = plt.setp(legend.get_title(), fontsize=LABEL_FONT_SIZE)\n",
    "\n",
    "# Save the final product.\n",
    "plt.savefig(VIZ_FILENAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ha9JUIN0B-M9"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hcds-a1-data-curation.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
